{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.tabular.all import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "\n",
    "from fastai.imports import *\n",
    "np.set_printoptions(linewidth=130)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,StackingClassifier\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,mean_squared_error, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "#transformers and pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')\n",
    "\n",
    "from fastkaggle import setup_comp\n",
    "\n",
    "\n",
    "\n",
    "from openfe import OpenFE, transform\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "import gc\n",
    "\n",
    "from xgboost import plot_importance\n",
    "import wandb\n",
    "from fastai.callback.wandb import *\n",
    "from wandb.integration.lightgbm import wandb_callback, log_summary\n",
    "#from wandb.xgboost import wandb_callback\n",
    "\n",
    "\n",
    "\n",
    "#from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('playground-series-s4e8')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('playground-series-s4e8/')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path/'train.csv',index_col='id')\n",
    "test_df = pd.read_csv(path/'test.csv',index_col='id')\n",
    "sub_df = pd.read_csv(path/'sample_submission.csv')\n",
    "secondary_data = pd.read_csv(path/'secondary_data.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3116945, 21)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, secondary_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61069, 21)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3178014, 21)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the training dataframe to avoid modifying the original\n",
    "train_df_with_nan = train_df.copy()\n",
    "\n",
    "# Add a NaN value to a random row in the 'stem-height' column\n",
    "random_index = np.random.choice(train_df_with_nan.index)\n",
    "train_df_with_nan.loc[random_index, 'stem-height'] = np.nan\n",
    "\n",
    "# Verify the NaN was added\n",
    "print(train_df_with_nan['stem-height'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names,cat_names = cont_cat_split(train_df_with_nan, dep_var='class')\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(train_df_with_nan))\n",
    "to = TabularPandas(train_df_with_nan, procs=[Categorify, FillMissing,Normalize],\n",
    "                   cat_names = cat_names,\n",
    "                   cont_names = cont_names,\n",
    "                   y_names='class',\n",
    "                   y_block=CategoryBlock(),\n",
    "                   splits=splits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=64)\n",
    "#dls = to.dataloaders(bs=1024)\n",
    "test_dl = dls.test_dl(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
    "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         class  cap-diameter  cap-shape  cap-surface  cap-color  \\\n",
       "id                                                                \n",
       "1681611      0      0.670730         72           57         64   \n",
       "2350766      1      2.258231         68           65         64   \n",
       "1550206      0     -0.721286         49           82         64   \n",
       "1458491      1      0.172354         64            0         56   \n",
       "1716987      0     -0.124094         72           73         64   \n",
       "...        ...           ...        ...          ...        ...   \n",
       "1213135      0      0.597693         68           54         58   \n",
       "349856       1      0.067093         49           77         75   \n",
       "1737173      0     -0.212169         72            0         62   \n",
       "1100809      0     -0.658989         54           57         64   \n",
       "2879497      1     -0.540840         72           57         65   \n",
       "\n",
       "         does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "id                                                                         \n",
       "1681611                    21               67             0          47   \n",
       "2350766                     9               48            29          62   \n",
       "1550206                     9                0            29          47   \n",
       "1458491                     9               54            35          37   \n",
       "1716987                     9               76            29          60   \n",
       "...                       ...              ...           ...         ...   \n",
       "1213135                     9               48            29          60   \n",
       "349856                      9               53            29          60   \n",
       "1737173                     9               48             0          50   \n",
       "1100809                     9                0            29          44   \n",
       "2879497                     9               45            29          47   \n",
       "\n",
       "         stem-height  stem-width  stem-root  stem-surface  stem-color  \\\n",
       "id                                                                      \n",
       "1681611     1.059699    0.936085          0             0          47   \n",
       "2350766    -0.028951    3.330971          0            45          44   \n",
       "1550206    -0.043762   -1.027745          0             0          56   \n",
       "1458491    -1.391614    1.437542          0            40          47   \n",
       "1716987     0.463533   -0.085353          0            52          47   \n",
       "...              ...         ...        ...           ...         ...   \n",
       "1213135     0.685707    1.544997         31             0          56   \n",
       "349856      2.233514   -0.010012          0            59          56   \n",
       "1737173    -0.358508   -0.474414          0             0          45   \n",
       "1100809    -0.099306   -0.576929          0            52          56   \n",
       "2879497    -0.702877   -0.610277          0            59          48   \n",
       "\n",
       "         veil-type  veil-color  has-ring  ring-type  spore-print-color  \\\n",
       "id                                                                       \n",
       "1681611          0          22        19         28                  0   \n",
       "2350766          0           0         6         19                  0   \n",
       "1550206          0           0         6         19                  0   \n",
       "1458491          0           0         6         19                  0   \n",
       "1716987          0           0         6         19                  0   \n",
       "...            ...         ...       ...        ...                ...   \n",
       "1213135          0           0         6         19                  0   \n",
       "349856          20          22        19         18                  0   \n",
       "1737173          0           0         6         19                  0   \n",
       "1100809          0           0         6         19                 18   \n",
       "2879497          0           0        19         40                  0   \n",
       "\n",
       "         habitat  season  cap-diameter_na  stem-height_na  \n",
       "id                                                         \n",
       "1681611       26       1                1               1  \n",
       "2350766       26       1                1               1  \n",
       "1550206       26       3                1               1  \n",
       "1458491       26       2                1               1  \n",
       "1716987       37       3                1               1  \n",
       "...          ...     ...              ...             ...  \n",
       "1213135       26       4                1               1  \n",
       "349856        26       1                1               1  \n",
       "1737173       37       3                1               1  \n",
       "1100809       26       1                1               1  \n",
       "2879497       26       4                1               1  \n",
       "\n",
       "[3116945 rows x 23 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3116945, 21)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_with_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2493556, 22)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=MatthewsCorrCoef())\n",
    "#learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = learn.load('mushroom_prediction_model_colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_optuna_params = {\n",
    "              \n",
    "    'num_leaves': 375, \n",
    "    'learning_rate': 0.0071851097672265855, \n",
    "    'n_estimators': 1851, \n",
    "    'subsample_for_bin': 104472,\n",
    "    'min_child_samples': 454,\n",
    "    'reg_alpha': 0.0011093389440775324,\n",
    "    'reg_lambda': 0.15936937364526085,\n",
    "    'colsample_bytree': 0.4533510196891779,\n",
    "    'subsample': 0.9272807625455266,\n",
    "    'max_depth': 20,\n",
    "    'min_child_weight': 4,\n",
    "    'gamma': 0.0033558210410357075,\n",
    "    'max_leaves': 873,\n",
    "    \n",
    "    #'device': 'gpu'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "lgbm_params = {\n",
    "    #'n_estimators': 2500,\n",
    "    'n_estimators': 5000,\n",
    "    'learning_rate': 0.16946407558813623,\n",
    "    'num_leaves': 120,\n",
    "    'max_depth': 5,\n",
    "    'min_data_in_leaf': 9400,\n",
    "    'max_bin': 300,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 100,\n",
    "    'min_gain_to_split': 0.12639861649831552,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "lgbm_params = {\n",
    "    #'n_estimators': 2500,\n",
    "    'num_leaves': 227,\n",
    "    'learning_rate': 0.06737922153052582,\n",
    "    'n_estimators': 357,\n",
    "    'subsample_for_bin': 213892,\n",
    "    'min_child_samples': 292,\n",
    "    'reg_alpha': 4.5070762908503614e-07,\n",
    "    'reg_lambda': 0.00017079711660762664,\n",
    "    'colsample_bytree': 0.45636430645506504,\n",
    "    'subsample': 0.6819598716671345,\n",
    "    'max_depth': 14\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1041,\n",
    "    'learning_rate': 0.08777255350163136,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 0.1259643500248322,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'random_strength': 4.276181166674371e-08,\n",
    "    'bagging_temperature': 0.35995482350907326,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 39,\n",
    "    \"verbose\": False,\n",
    "    \"allow_writing_files\": False,\n",
    "    #\"task_type\": 'GPU',\n",
    "    \"cat_features\": cat_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(**xgb_optuna_params)\n",
    "#xgb_model = xgb_model.fit(X_train, y_train)\n",
    "rf_model = RandomForestClassifier(500, min_samples_leaf=3)\n",
    "#rf_model = rf.fit(X_train, y_train)\n",
    "lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "#lgbm_model = lgbm_model.fit(X_train, y_train)\n",
    "cat_model = CatBoostClassifier(**cat_params)\n",
    "#cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch\n",
    "\n",
    "class FastaiLearnerWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learner):\n",
    "        self.learner = learner\n",
    "        self.classes_ = np.array(self.learner.dls.vocab)  # Assuming binary classification\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Since the learner is already trained, we don't need to do anything here\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert input to fastai DataLoader\n",
    "        X_dl = self.learner.dls.test_dl(X)\n",
    "        # Get predictions\n",
    "        _, preds, _ = self.learner.get_preds(dl=X_dl, with_decoded=True)\n",
    "        return preds.numpy().argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Convert input to fastai DataLoader\n",
    "        X_dl = self.learner.dls.test_dl(X)\n",
    "        # Get predictions\n",
    "        preds, _, _ = self.learner.get_preds(dl=X_dl, with_decoded=True)\n",
    "        return preds.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_wrapper = FastaiLearnerWrapper(learn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1364536, number of negative: 1129020\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.182254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189464\n",
      "[LightGBM] [Info] Start training from score 0.189464\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FastaiLearnerWrapper' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:18\u001b[0m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:349\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    347\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_base.py:36\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 36\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(X, y)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FastaiLearnerWrapper' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Assuming rf_model and xgb_model are already fitted models\n",
    "# Wrap them in a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),  # Replace rf_model with the actual RandomForestClassifier instance\n",
    "    ('xgb', xgb_model),  # Replace xgb_model with the actual XGBoostClassifier instance\n",
    "    ('cat', cat_model),  # Replace rf_model with the actual RandomForestClassifier instance\n",
    "    ('lgb', lgbm_model),\n",
    "    ('nn', nn_model_wrapper)\n",
    "    #('nn', nn_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Now, you can use the VotingClassifier to make predictions\n",
    "# Note: The VotingClassifier expects scikit-learn compatible inputs\n",
    "# So, you'll need to convert your PyTorch tensors to NumPy arrays or Pandas DataFrames\n",
    "# Here's an example assuming X_test is your test data in a PyTorch tensor format\n",
    "#X_test_np = X_test.numpy()  # Convert PyTorch tensor to NumPy array\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "#predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "#print(f\"Accuracy: {accuracy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:366\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    364\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 366\u001b[0m     maj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'hard' voting\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:407\u001b[0m, in \u001b[0;36mVotingClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    Weighted average probability for each class per sample.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    406\u001b[0m avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_probas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights_not_none\n\u001b[1;32m    408\u001b[0m )\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:382\u001b[0m, in \u001b[0;36mVotingClassifier._collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_collect_probas\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([clf\u001b[38;5;241m.\u001b[39mpredict_proba(X) \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = voting_clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "voting_score = matthews_corrcoef(y_test, predictions)\n",
    "voting_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:366\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    364\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 366\u001b[0m     maj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'hard' voting\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:407\u001b[0m, in \u001b[0;36mVotingClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    Weighted average probability for each class per sample.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    406\u001b[0m avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_probas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights_not_none\n\u001b[1;32m    408\u001b[0m )\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:382\u001b[0m, in \u001b[0;36mVotingClassifier._collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_collect_probas\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([clf\u001b[38;5;241m.\u001b[39mpredict_proba(X) \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "voting_preds = voting_clf.predict(test_dl.xs)\n",
    "voting_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mpredictions\u001b[49m)\n\u001b[1;32m      2\u001b[0m voting_preds_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(voting_preds)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_tensor = torch.from_numpy(predictions)\n",
    "voting_preds_tensor = torch.from_numpy(voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutogluonModels  playground-series-s4e8\t\t     wandb\n",
      "lgbm_model.pkl\t playground-series-s4e8.zip\t     xgb_model.json\n",
      "main.py\t\t poisonous_mushrooms_classification\n",
      "models\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in voting_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 46.7MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[VOTING CLASSIFIER] Silver Rubanza, VOTING CLASSIFIER soft voting + nn sub 6 XGB,LGBM rabbit params 357 estimators,RF sub 2  - lightning  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_estimators = [\n",
    "    ('cat_boost',cat_model),\n",
    "    ('rf',rf_model),\n",
    "    ('lgbm',lgbm_model),\n",
    "    ('xgb',xgb_model),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(\n",
    "    estimators=stacking_estimators,\n",
    "    final_estimator=xgb.XGBClassifier(**xgb_optuna_params),\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1364536, number of negative: 1129020\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189464\n",
      "[LightGBM] [Info] Start training from score 0.189464\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.12639861649831552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.12639861649831552\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "stacking_preds_x = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.12639861649831552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.12639861649831552\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "stacking_preds = (clf.predict(test_dl.xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stacking_score = matthews_corrcoef(y_test,stacking_preds_x)\n",
    "stacking_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in stacking_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[STACKING ENSEMBLE] Silver Rubanza,  Stacking ensemble sub 2 -cat,rf,xgb,lgbm  - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 14s, sys: 952 ms, total: 26min 15s\n",
      "Wall time: 13min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9847934802058209"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(**xgb_optuna_params)\n",
    "xgb_model = xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
    "\n",
    "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
    "\n",
    "xgb_score = matthews_corrcoef(y_test,xgb_preds_x)\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MCC: 0.9848125210262535\n",
      "Fold 2 MCC: 0.984771543207258\n",
      "Fold 3 MCC: 0.9848196377390515\n",
      "Fold 4 MCC: 0.9843472414002526\n",
      "Fold 5 MCC: 0.9848755447755988\n",
      "Mean MCC: 0.984725297629683\n",
      "CPU times: user 1h 8min 22s, sys: 3.48 s, total: 1h 8min 26s\n",
      "Wall time: 35min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Train the model on the current fold\n",
    "    xgb_model_fold = xgb.XGBClassifier(**xgb_optuna_params)\n",
    "    xgb_model_fold.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Predict on the validation set for the current fold\n",
    "    y_pred_fold = xgb_model_fold.predict(X_fold_val)\n",
    "    y_pred_fold_tt = xgb_model_fold.predict(test_dl.xs)\n",
    "    \n",
    "    # Calculate and store the Matthews Correlation Coefficient for the current fold\n",
    "    score = matthews_corrcoef(y_fold_val, y_pred_fold)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold} MCC: {score}\")\n",
    "\n",
    "# Calculate and print the mean score across all folds\n",
    "mean_score = np.mean(fold_scores)\n",
    "print(f\"Mean MCC: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9816297021275638"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without original dataset\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9847934802058209, 0.984725297629683)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with original dataset\n",
    "xgb_score,mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847901835973488"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with original dataset - 2000 estimators\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fold_tt = xgb_model_fold.predict(test_dl.xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846685637768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846685637768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3rd trial\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847493710839511"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">0.9847493710839511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in xgb_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 44.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[XGBoost Cross Val PREDS] Silver Rubanza,  XGBoost optuna tuned preds + original dataset with cross validation  - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=MatthewsCorrCoef())\n",
    "#learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('mushroom_prediction_model_colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3,wd=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.043609</td>\n",
       "      <td>0.039497</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.983664</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.983683</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > 9.35 BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1364536, number of negative: 1129020\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.224300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189464\n",
      "[LightGBM] [Info] Start training from score 0.189464\n",
      "CPU times: user 3min 40s, sys: 750 ms, total: 3min 41s\n",
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9844770580395102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#ds subset\n",
    "lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "lgbm_model = lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "#test set preds\n",
    "lgbm_preds = tensor(lgbm_model.predict(test_dl.xs))\n",
    "\n",
    "#validation set preds\n",
    "lgbm_preds_x = tensor(lgbm_model.predict(X_test))\n",
    "\n",
    "\n",
    "#lgb_preds_x_prob = tensor(lgb_model.predict_proba(X_test))\n",
    "\n",
    "lgbm_score = matthews_corrcoef(y_test,lgbm_preds_x)\n",
    "lgbm_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1091628, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994844, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189464\n",
      "[LightGBM] [Info] Start training from score 0.189464\n",
      "Fold 1 MCC: 0.9845946642646747\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.160764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 974\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 2 MCC: 0.9846691496099631\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 971\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 3 MCC: 0.9843293150327277\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 984\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 4 MCC: 0.9847253996606858\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 5 MCC: 0.9840828649412983\n",
      "Mean MCC: 0.9844802787018698\n",
      "CPU times: user 9min 42s, sys: 1.34 s, total: 9min 44s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Train the model on the current fold\n",
    "    lgbm_model_fold = lgb.LGBMClassifier(**lgbm_params)\n",
    "    lgbm_model_fold.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Predict on the validation set for the current fold\n",
    "    y_pred_fold = lgbm_model_fold.predict(X_fold_val)\n",
    "    \n",
    "    # Calculate and store the Matthews Correlation Coefficient for the current fold\n",
    "    score = matthews_corrcoef(y_fold_val, y_pred_fold)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold} MCC: {score}\")\n",
    "\n",
    "# Calculate and print the mean score across all folds\n",
    "mean_score = np.mean(fold_scores)\n",
    "print(f\"Mean MCC: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9845321298854594\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9844770580395102\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT NANS- USING FILL MISSING\n",
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MCC: 0.9845217158539917\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MCC: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MCC: 0.9844802787018698\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT NANS USING FILLMISSING\n",
    "print(f\"Mean MCC: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LGBM MCC on test set: 0.9844417245982304\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final LGBM MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9841022260741565\n"
     ]
    }
   ],
   "source": [
    "#10000 estimators\n",
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9841250711521743\n"
     ]
    }
   ],
   "source": [
    "#5000 estimators\n",
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9840244628142798\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in lgbm_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 48.5MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[LGBM PREDS] Silver Rubanza,  SUJAY OPTUNA  - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGB-LGBM MCC on test set: 0.9843371651003854\n"
     ]
    }
   ],
   "source": [
    "xgb_lgbm = (lgbm_preds_x + xgb_preds_x)/2\n",
    "rounded_xgb_lgbm_preds = torch.round(xgb_lgbm).long()\n",
    "xgb_lgbm_score = matthews_corrcoef(y_test,rounded_xgb_lgbm_preds)\n",
    "print(f\"Final XGB-LGBM MCC on test set: {xgb_lgbm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Final XGB-LGBM MCC on test set: 0.9842722905541913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tensor = torch.from_numpy(predictions)\n",
    "voting_preds_tensor = torch.from_numpy(voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([623389]), torch.Size([623389]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tensor.shape,xgb_preds_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting preds + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGB-VOTING MCC on test set: 0.9846285430578156\n"
     ]
    }
   ],
   "source": [
    "xgb_voting_clf = (predictions_tensor + xgb_preds_x)/2\n",
    "rounded_xgb_voting_clf_preds = torch.round(xgb_voting_clf).long()\n",
    "xgb_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting preds + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LGBM-VOTING MCC on test set: 0.9842323739641381\n"
     ]
    }
   ],
   "source": [
    "lgbm_voting_clf = (predictions_tensor + lgbm_preds_x)/2\n",
    "rounded_lgbm_voting_clf_preds = torch.round(lgbm_voting_clf).long()\n",
    "lgbm_voting_clf_score = matthews_corrcoef(y_test,rounded_lgbm_voting_clf_preds)\n",
    "print(f\"Final LGBM-VOTING MCC on test set: {lgbm_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting preds + XGB + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final xgb-LGBM-VOTING MCC on test set: 0.9845939235730832\n"
     ]
    }
   ],
   "source": [
    "xgb_lgbm_voting_clf = (predictions_tensor + lgbm_preds_x + xgb_preds_x)/3\n",
    "rounded_xgb_lgbm_voting_clf_preds = torch.round(xgb_lgbm_voting_clf).long()\n",
    "xgb_lgbm_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_lgbm_voting_clf_preds)\n",
    "print(f\"Final xgb-LGBM-VOTING MCC on test set: {xgb_lgbm_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB + STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds_x.shape,stacking_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_clf = (stacking_preds_x + xgb_preds_x)/2\n",
    "rounded_xgb_voting_clf_preds = torch.round(xgb_voting_clf).long()\n",
    "xgb_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_stacking_clf = (stacking_preds_x + xgb_preds_x)/2\n",
    "rounded_xgb_stacking_clf_preds = torch.round(xgb_stacking_clf).long()\n",
    "xgb_stacking_clf_score = matthews_corrcoef(y_test,rounded_xgb_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB + STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_stacking_clf = (stacking_preds_x + xgb_preds_x + predictions_tensor)/3\n",
    "rounded_xgb_voting_stacking_clf_preds = torch.round(xgb_voting_stacking_clf).long()\n",
    "xgb_voting_stacking_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB + LGBM + STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lgbm_voting_stacking_clf = (stacking_preds_x + xgb_preds_x + lgbm_preds_x + predictions_tensor)/4\n",
    "rounded_xgb_lgbm_voting_stacking_clf_preds = torch.round(xgb_lgbm_voting_stacking_clf).long()\n",
    "xgb_lgbm_voting_stacking_clf_score = matthews_corrcoef(y_test,rounded_xgb_lgbm_voting_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM + STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_voting_stacking_clf = (stacking_preds_x + lgbm_preds_x + predictions_tensor)/3\n",
    "rounded_lgbm_voting_stacking_clf_preds = torch.round(lgbm_voting_stacking_clf).long()\n",
    "xgb_voting_stacking_clf_score = matthews_corrcoef(y_test,rounded_lgbm_voting_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_voting_clf = (stacking_preds_x + predictions_tensor)/2\n",
    "rounded_stacking_voting_clf_preds = torch.round(stacking_voting_clf).long()\n",
    "stacking_voting_clf_score = matthews_corrcoef(y_test,rounded_stacking_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {stacking_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final XGB-VOTING MCC on test set: {stacking_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_clf = (predictions_tensor + xgb_preds_x)/2\n",
    "rounded_xgb_voting_clf_preds = torch.round(xgb_voting_clf).long()\n",
    "xgb_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_d = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING',\n",
    "    'XGB-VOTING','XGB-STACKING','XGB-VOTING-STACKING','XGB-LGBM-VOTING-STACKING','LGBM-VOTING-STACKING','STACKING-VOTING'],\n",
    "    'mcc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,\n",
    "    lgbm_voting_clf_score,xgb_voting_clf_score,xgb_stacking_clf_score,xgb_voting_stacking_clf_score,\n",
    "    xgb_lgbm_voting_stacking_clf_score,lgbm_voting_stacking_clf_score,stacking_voting_clf_score ]\n",
    "})\n",
    "\n",
    "mcc_sorted_d = mcc_d.sort_values(by='mcc_d', ascending=False)\n",
    "mcc_sorted_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algoritm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.984749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB-VOTING</td>\n",
       "      <td>0.984629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb-LGBM-VOTING</td>\n",
       "      <td>0.984594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-LGBM</td>\n",
       "      <td>0.984337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM-VOTING</td>\n",
       "      <td>0.984232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.984125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          algoritm       acc\n",
       "1          xgboost  0.984749\n",
       "5       XGB-VOTING  0.984629\n",
       "3  xgb-LGBM-VOTING  0.984594\n",
       "2         XGB-LGBM  0.984337\n",
       "4      LGBM-VOTING  0.984232\n",
       "0             lgbm  0.984125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING'],\n",
    "    'MCC': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9843371651003854, 0.9841250711521743, 0.9847493710839511)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lgbm_score,lgbm_score,xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algoritm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.984749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-LGBM</td>\n",
       "      <td>0.984272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.984024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algoritm       acc\n",
       "1   xgboost  0.984749\n",
       "2  XGB-LGBM  0.984272\n",
       "0      lgbm  0.984024"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost','XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_a = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING',\n",
    "    'XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,\n",
    "    lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING','VOTING','STACKING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score,voting_score,stacking_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algoritm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.984749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB-VOTING</td>\n",
       "      <td>0.984629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb-LGBM-VOTING</td>\n",
       "      <td>0.984594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-LGBM</td>\n",
       "      <td>0.984337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM-VOTING</td>\n",
       "      <td>0.984232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.984125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          algoritm       acc\n",
       "1          xgboost  0.984749\n",
       "5       XGB-VOTING  0.984629\n",
       "3  xgb-LGBM-VOTING  0.984594\n",
       "2         XGB-LGBM  0.984337\n",
       "4      LGBM-VOTING  0.984232\n",
       "0             lgbm  0.984125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'cat_boost', 'xgboost + lgbm ', 'xgboost + lgbm + cat_boost',\n",
    "     'xgboost + cat_boost', 'lgbm + cat_boost','neural_network','xgb + nn',\n",
    "     'nn_score + lgbm + xgb + cat','nn_score + lgbm + cat','nn_score + xgb + cat' ],\n",
    "    'acc': [lgbm_score, xgb_score, cat_score,xgb_lgbm_score,xgb_lgbm_cat_score,\n",
    "    xgb_cat_score,lgbm_cat_score, nn_score,xgb_nn_a_score,xgb_lgbm_cat_nn_score, lgbm_cat_nn_score,xgb_cat_nn_score ]\n",
    "})\n",
    "\n",
    "accuracy_sorted = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lgbm_sub = (xgb_preds + lgbm_preds)/2\n",
    "rounded_xgb_lgbm_sub_preds = torch.round(xgb_lgbm_sub).long()\n",
    "rounded_xgb_lgbm_sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in rounded_xgb_lgbm_sub_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 42.7MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[XGBOOST+LGBM] Silver Rubanza, XGBOOST + SUJAY 5000 estimators LGBM optuna tuned params - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM, XGB + VOTING PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2077964,), torch.Size([2077964]), torch.Size([2077964]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_preds.shape,lgbm_preds.shape,xgb_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB + VOTING CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_voting_clf_sub = (xgb_preds + voting_preds)/2\n",
    "rounded_xgb_voting_clf_sub_preds = torch.round(xgb_voting_clf_sub).long()\n",
    "rounded_xgb_voting_clf_sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'submission.csv': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in rounded_xgb_voting_clf_sub_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 45.6MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[XGBOOST+VOTING CLASSIFIER] Silver Rubanza, XGBOOST + VOTING CLASSIFIER PREDS sub 3 - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB + LBM + VOTING CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lgbm_voting_clf_sub = (xgb_preds + voting_preds+ lgbm_preds)/3\n",
    "rounded_xgb_lgbm_voting_clf_sub_preds = torch.round(xgb_lgbm_voting_clf_sub).long()\n",
    "rounded_xgb_voting_clf_sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in rounded_xgb_lgbm_voting_clf_sub_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 46.1MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[XGBOOST+LGBM+VOTING] Silver Rubanza, XGBOOST + SUJAY LGBM optuna tuned params - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM + VOTING CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_voting_clf_sub = (lgbm_preds + voting_preds)/2\n",
    "rounded_lgbm_voting_clf_sub_preds = torch.round(lgbm_voting_clf_sub).long()\n",
    "rounded_lgbm_voting_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + xgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_stacking_clf_sub = (xgb_preds + stacking_preds)/2\n",
    "rounded_xgb_stacking_clf_sub_preds = torch.round(xgb_stacking_clf_sub ).long()\n",
    "rounded_xgb_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_stacking_clf_sub = (lgbm_preds + stacking_preds)/2\n",
    "rounded_lgbm_stacking_clf_sub_preds = torch.round(lgbm_stacking_clf_sub ).long()\n",
    "rounded_lgbm_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_stacking_clf_sub = (voting_preds + stacking_preds)/2\n",
    "rounded_voting_stacking_clf_sub_preds = torch.round(voting_stacking_clf_sub ).long()\n",
    "rounded_voting_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_stacking_clf_sub = (voting_preds + stacking_preds + xgb_preds)/3\n",
    "rounded_xgb_voting_stacking_clf_sub_preds = torch.round(xgb_voting_stacking_clf_sub ).long()\n",
    "rounded_xgb_voting_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting + XGB + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lgbm_voting_stacking_clf_sub = (voting_preds + stacking_preds + xgb_preds + lgbm_preds)/4\n",
    "rounded_xgb_lgbm_voting_stacking_clf_sub_preds = torch.round(xgb_lgbm_voting_stacking_clf_sub ).long()\n",
    "rounded_xgb_lgbm_voting_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_voting_stacking_clf_sub = (voting_preds + stacking_preds + lgbm_preds)/3\n",
    "rounded_lgbm_voting_stacking_clf_sub_preds = torch.round(lgbm_voting_stacking_clf_sub ).long()\n",
    "rounded_lgbm_voting_stacking_clf_sub_preds"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
