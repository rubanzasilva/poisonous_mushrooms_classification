{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.tabular.all import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "\n",
    "from fastai.imports import *\n",
    "np.set_printoptions(linewidth=130)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,StackingClassifier\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,mean_squared_error, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "#transformers and pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')\n",
    "\n",
    "from fastkaggle import setup_comp\n",
    "\n",
    "\n",
    "\n",
    "from openfe import OpenFE, transform\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "import gc\n",
    "\n",
    "from xgboost import plot_importance\n",
    "import wandb\n",
    "from fastai.callback.wandb import *\n",
    "from wandb.integration.lightgbm import wandb_callback, log_summary\n",
    "#from wandb.xgboost import wandb_callback\n",
    "\n",
    "\n",
    "\n",
    "#from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('playground-series-s4e8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('playground-series-s4e8/')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path/'train.csv',index_col='id')\n",
    "test_df = pd.read_csv(path/'test.csv',index_col='id')\n",
    "sub_df = pd.read_csv(path/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the training dataframe to avoid modifying the original\n",
    "train_df_with_nan = train_df.copy()\n",
    "\n",
    "# Add a NaN value to a random row in the 'stem-height' column\n",
    "random_index = np.random.choice(train_df_with_nan.index)\n",
    "train_df_with_nan.loc[random_index, 'stem-height'] = np.nan\n",
    "\n",
    "# Verify the NaN was added\n",
    "print(train_df_with_nan['stem-height'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names,cat_names = cont_cat_split(train_df_with_nan, dep_var='class')\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(train_df_with_nan))\n",
    "to = TabularPandas(train_df_with_nan, procs=[Categorify, FillMissing,Normalize],\n",
    "                   cat_names = cat_names,\n",
    "                   cont_names = cont_names,\n",
    "                   y_names='class',\n",
    "                   y_block=CategoryBlock(),\n",
    "                   splits=splits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=64)\n",
    "#dls = to.dataloaders(bs=1024)\n",
    "test_dl = dls.test_dl(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
    "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         class  cap-diameter  cap-shape  cap-surface  cap-color  \\\n",
       "id                                                                \n",
       "547711       1     -0.948561         72           60         62   \n",
       "303590       1      0.451292         72           56         64   \n",
       "2524055      0     -1.040883         54           82         64   \n",
       "2096058      1      0.230150         49           77         75   \n",
       "2055442      1     -0.538481         49           77         64   \n",
       "...        ...           ...        ...          ...        ...   \n",
       "1931402      1     -1.032295         54           57         77   \n",
       "519767       1     -0.647979         72           60         56   \n",
       "1492903      0      9.543898         64           82         77   \n",
       "436728       1      0.599437         68           77         66   \n",
       "229552       1     -0.115519         72           48         64   \n",
       "\n",
       "         does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "id                                                                         \n",
       "547711                      9               45             0          49   \n",
       "303590                      9               53             0          60   \n",
       "2524055                     9               45            32          49   \n",
       "2096058                     9               53            29          60   \n",
       "2055442                     9               76            29          49   \n",
       "...                       ...              ...           ...         ...   \n",
       "1931402                     9                0             0          62   \n",
       "519767                      9                0             0          35   \n",
       "1492903                     9               67             0          62   \n",
       "436728                     21               48            29          49   \n",
       "229552                     21               48            29          60   \n",
       "\n",
       "         stem-height  stem-width  stem-root  stem-surface  stem-color  \\\n",
       "id                                                                      \n",
       "547711     -0.851246   -1.081126          0             0          56   \n",
       "303590      0.741772    0.548564          0            59          56   \n",
       "2524055    -0.380750   -0.940273          0            55          47   \n",
       "2096058     2.197716    0.090175          0            59          56   \n",
       "2055442    -0.380750   -0.899500          0            44          39   \n",
       "...              ...         ...        ...           ...         ...   \n",
       "1931402    -0.195515   -1.107072          0             0          58   \n",
       "519767     -0.647488   -0.677101          0             0          36   \n",
       "1492903     0.160135    2.868925          0            45          44   \n",
       "436728      0.734362    0.696830          0             0          49   \n",
       "229552      0.471329   -0.260721          0             0          47   \n",
       "\n",
       "         veil-type  veil-color  has-ring  ring-type  spore-print-color  \\\n",
       "id                                                                       \n",
       "547711           0           0         6         19                 23   \n",
       "303590          20          22        19         28                  0   \n",
       "2524055          0           0         6         19                  0   \n",
       "2096058          0           0        19         18                  0   \n",
       "2055442          0           0         6         19                  0   \n",
       "...            ...         ...       ...        ...                ...   \n",
       "1931402          0           0         6         19                  0   \n",
       "519767           0           0         6         19                 21   \n",
       "1492903          0           0         6         19                  0   \n",
       "436728           0           0        19         19                  0   \n",
       "229552           0           0         6         19                  0   \n",
       "\n",
       "         habitat  season  cap-diameter_na  stem-height_na  \n",
       "id                                                         \n",
       "547711        30       1                1               1  \n",
       "303590        26       3                1               1  \n",
       "2524055       31       3                1               1  \n",
       "2096058       26       3                1               1  \n",
       "2055442       26       3                1               1  \n",
       "...          ...     ...              ...             ...  \n",
       "1931402       30       1                1               1  \n",
       "519767        26       1                1               1  \n",
       "1492903       26       3                1               1  \n",
       "436728        26       1                1               1  \n",
       "229552        26       1                1               1  \n",
       "\n",
       "[3116945 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3116945, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_with_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2493556, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.tabular.data.TabularDataLoaders at 0x7f960c452d70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=MatthewsCorrCoef())\n",
    "#learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = learn.load('mushroom_prediction_model_colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_optuna_params = {\n",
    "              \n",
    "    'num_leaves': 375, \n",
    "    'learning_rate': 0.0071851097672265855, \n",
    "    'n_estimators': 100, \n",
    "    'subsample_for_bin': 104472,\n",
    "    'min_child_samples': 454,\n",
    "    'reg_alpha': 0.0011093389440775324,\n",
    "    'reg_lambda': 0.15936937364526085,\n",
    "    'colsample_bytree': 0.4533510196891779,\n",
    "    'subsample': 0.9272807625455266,\n",
    "    'max_depth': 20,\n",
    "    'min_child_weight': 4,\n",
    "    'gamma': 0.0033558210410357075,\n",
    "    'max_leaves': 873,\n",
    "    \n",
    "    #'device': 'gpu'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "lgbm_params = {\n",
    "    #'n_estimators': 2500,\n",
    "    'n_estimators': 5000,\n",
    "    'learning_rate': 0.16946407558813623,\n",
    "    'num_leaves': 120,\n",
    "    'max_depth': 5,\n",
    "    'min_data_in_leaf': 9400,\n",
    "    'max_bin': 300,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 100,\n",
    "    'min_gain_to_split': 0.12639861649831552,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "lgbm_params = {\n",
    "    #'n_estimators': 2500,\n",
    "    'num_leaves': 227,\n",
    "    'learning_rate': 0.06737922153052582,\n",
    "    'n_estimators': 357,\n",
    "    'subsample_for_bin': 213892,\n",
    "    'min_child_samples': 292,\n",
    "    'reg_alpha': 4.5070762908503614e-07,\n",
    "    'reg_lambda': 0.00017079711660762664,\n",
    "    'colsample_bytree': 0.45636430645506504,\n",
    "    'subsample': 0.6819598716671345,\n",
    "    'max_depth': 14\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1041,\n",
    "    'learning_rate': 0.08777255350163136,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 0.1259643500248322,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'random_strength': 4.276181166674371e-08,\n",
    "    'bagging_temperature': 0.35995482350907326,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 39,\n",
    "    \"verbose\": False,\n",
    "    \"allow_writing_files\": False,\n",
    "    #\"task_type\": 'GPU',\n",
    "    \"cat_features\": cat_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(**xgb_optuna_params)\n",
    "#xgb_model = xgb_model.fit(X_train, y_train)\n",
    "rf_model = RandomForestClassifier(500, min_samples_leaf=3)\n",
    "#rf_model = rf.fit(X_train, y_train)\n",
    "lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "#lgbm_model = lgbm_model.fit(X_train, y_train)\n",
    "cat_model = CatBoostClassifier(**cat_params)\n",
    "#cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class FastAIWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learn):\n",
    "        self.learn = learn\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # FastAI model is already trained, so we don't need to do anything here\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        dl = self.learn.dls.test_dl(X)\n",
    "        preds, _ = self.learn.get_preds(dl=dl)\n",
    "        return preds.cpu()  # Return PyTorch tensor\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return torch.argmax(proba, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class FastAIWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learn, device='cpu'):\n",
    "        self.learn = learn\n",
    "        self.device = torch.device(device)\n",
    "        self.learn.model = self.learn.model.to(self.device)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # FastAI model is already trained, so we don't need to do anything here\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        dl = self.learn.dls.test_dl(X)\n",
    "        preds, _ = self.learn.get_preds(dl=dl)\n",
    "        return torch.argmax(preds, dim=1).to('cpu')\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        dl = self.learn.dls.test_dl(X)\n",
    "        preds, _ = self.learn.get_preds(dl=dl)\n",
    "        return preds.to('cpu')\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = torch.device(device)\n",
    "        self.learn.model = self.learn.model.to(self.device)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CPU\n",
    "nn_model_cpu = FastAIWrapper(learn, device='cpu')\n",
    "\n",
    "# For GPU (if available)\n",
    "nn_model_gpu = FastAIWrapper(learn, device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = FastAIWrapper(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Assuming rf_model and xgb_model are already fitted models\n",
    "# Wrap them in a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),  # Replace rf_model with the actual RandomForestClassifier instance\n",
    "    ('xgb', xgb_model),  # Replace xgb_model with the actual XGBoostClassifier instance\n",
    "    ('cat', cat_model),  # Replace rf_model with the actual RandomForestClassifier instance\n",
    "    ('lgb', lgbm_model),\n",
    "    ('nn', nn_model_cpu)\n",
    "    #('nn', nn_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Now, you can use the VotingClassifier to make predictions\n",
    "# Note: The VotingClassifier expects scikit-learn compatible inputs\n",
    "# So, you'll need to convert your PyTorch tensors to NumPy arrays or Pandas DataFrames\n",
    "# Here's an example assuming X_test is your test data in a PyTorch tensor format\n",
    "#X_test_np = X_test.numpy()  # Convert PyTorch tensor to NumPy array\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "#predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "#print(f\"Accuracy: {accuracy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 47s, sys: 115 ms, total: 4min 47s\n",
      "Wall time: 2min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictions = voting_clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.3 ms, sys: 4.12 ms, total: 95.4 ms\n",
      "Wall time: 99.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9846667795211294"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "voting_score = matthews_corrcoef(y_test, predictions)\n",
    "voting_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 54s, sys: 627 ms, total: 15min 54s\n",
      "Wall time: 9min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "voting_preds = voting_clf.predict(test_dl.xs)\n",
    "voting_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tensor = torch.from_numpy(predictions)\n",
    "voting_preds_tensor = torch.from_numpy(voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutogluonModels  playground-series-s4e8\t\t     wandb\n",
      "lgbm_model.pkl\t playground-series-s4e8.zip\t     xgb_model.json\n",
      "main.py\t\t poisonous_mushrooms_classification\n",
      "models\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in voting_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 46.7MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[VOTING CLASSIFIER] Silver Rubanza, VOTING CLASSIFIER hard voting sub 5 XGB,LGBM rabbit params 357 estimators,RF sub 2  - lightning  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_estimators = [\n",
    "    ('cat_boost',cat_model),\n",
    "    ('rf',rf_model),\n",
    "    ('lgbm',lgbm_model),\n",
    "    ('xgb',xgb_model),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(\n",
    "    estimators=stacking_estimators,\n",
    "    final_estimator=xgb.XGBClassifier(**xgb_optuna_params),\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1364536, number of negative: 1129020\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189464\n",
      "[LightGBM] [Info] Start training from score 0.189464\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.12639861649831552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.12639861649831552\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "stacking_preds_x = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.12639861649831552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.12639861649831552\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "stacking_preds = (clf.predict(test_dl.xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_score = matthews_corrcoef(y_test,stacking_preds_x)\n",
    "stacking_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in stacking_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[STACKING ENSEMBLE] Silver Rubanza,  Stacking ensemble sub 2 -cat,rf,xgb,lgbm  - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 229 ms, total: 1min 3s\n",
      "Wall time: 32.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9816297021275638"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(**xgb_optuna_params)\n",
    "xgb_model = xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
    "\n",
    "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
    "\n",
    "xgb_score = matthews_corrcoef(y_test,xgb_preds_x)\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846685637768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846685637768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3rd trial\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847493710839511"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">0.9847493710839511"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=MatthewsCorrCoef())\n",
    "#learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('mushroom_prediction_model_colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3,wd=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.043609</td>\n",
       "      <td>0.039497</td>\n",
       "      <td>0.983430</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.983664</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.983683</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > 9.35 BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1364536, number of negative: 1129020\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.224300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189464\n",
      "[LightGBM] [Info] Start training from score 0.189464\n",
      "CPU times: user 3min 40s, sys: 750 ms, total: 3min 41s\n",
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9844770580395102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#ds subset\n",
    "lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "lgbm_model = lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "#test set preds\n",
    "lgbm_preds = tensor(lgbm_model.predict(test_dl.xs))\n",
    "\n",
    "#validation set preds\n",
    "lgbm_preds_x = tensor(lgbm_model.predict(X_test))\n",
    "\n",
    "\n",
    "#lgb_preds_x_prob = tensor(lgb_model.predict_proba(X_test))\n",
    "\n",
    "lgbm_score = matthews_corrcoef(y_test,lgbm_preds_x)\n",
    "lgbm_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1091628, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 978\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994844, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189464\n",
      "[LightGBM] [Info] Start training from score 0.189464\n",
      "Fold 1 MCC: 0.9845946642646747\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.160764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 974\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 2 MCC: 0.9846691496099631\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 971\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 3 MCC: 0.9843293150327277\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 984\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 4 MCC: 0.9847253996606858\n",
      "[LightGBM] [Info] Number of positive: 1091629, number of negative: 903216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 1994845, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547225 -> initscore=0.189465\n",
      "[LightGBM] [Info] Start training from score 0.189465\n",
      "Fold 5 MCC: 0.9840828649412983\n",
      "Mean MCC: 0.9844802787018698\n",
      "CPU times: user 9min 42s, sys: 1.34 s, total: 9min 44s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Train the model on the current fold\n",
    "    lgbm_model_fold = lgb.LGBMClassifier(**lgbm_params)\n",
    "    lgbm_model_fold.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Predict on the validation set for the current fold\n",
    "    y_pred_fold = lgbm_model_fold.predict(X_fold_val)\n",
    "    \n",
    "    # Calculate and store the Matthews Correlation Coefficient for the current fold\n",
    "    score = matthews_corrcoef(y_fold_val, y_pred_fold)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold} MCC: {score}\")\n",
    "\n",
    "# Calculate and print the mean score across all folds\n",
    "mean_score = np.mean(fold_scores)\n",
    "print(f\"Mean MCC: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9845321298854594\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9844770580395102\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT NANS- USING FILL MISSING\n",
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MCC: 0.9845217158539917\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MCC: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MCC: 0.9844802787018698\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT NANS USING FILLMISSING\n",
    "print(f\"Mean MCC: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LGBM MCC on test set: 0.9844417245982304\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final LGBM MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9841022260741565\n"
     ]
    }
   ],
   "source": [
    "#10000 estimators\n",
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9841250711521743\n"
     ]
    }
   ],
   "source": [
    "#5000 estimators\n",
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Neural Network MCC on test set: 0.9840244628142798\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Neural Network MCC on test set: {lgbm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in lgbm_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 48.5MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[LGBM PREDS] Silver Rubanza,  SUJAY OPTUNA  - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGB-LGBM MCC on test set: 0.9843371651003854\n"
     ]
    }
   ],
   "source": [
    "xgb_lgbm = (lgbm_preds_x + xgb_preds_x)/2\n",
    "rounded_xgb_lgbm_preds = torch.round(xgb_lgbm).long()\n",
    "xgb_lgbm_score = matthews_corrcoef(y_test,rounded_xgb_lgbm_preds)\n",
    "print(f\"Final XGB-LGBM MCC on test set: {xgb_lgbm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Final XGB-LGBM MCC on test set: 0.9842722905541913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tensor = torch.from_numpy(predictions)\n",
    "voting_preds_tensor = torch.from_numpy(voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([623389]), torch.Size([623389]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tensor.shape,xgb_preds_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting preds + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGB-VOTING MCC on test set: 0.9846285430578156\n"
     ]
    }
   ],
   "source": [
    "xgb_voting_clf = (predictions_tensor + xgb_preds_x)/2\n",
    "rounded_xgb_voting_clf_preds = torch.round(xgb_voting_clf).long()\n",
    "xgb_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting preds + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LGBM-VOTING MCC on test set: 0.9842323739641381\n"
     ]
    }
   ],
   "source": [
    "lgbm_voting_clf = (predictions_tensor + lgbm_preds_x)/2\n",
    "rounded_lgbm_voting_clf_preds = torch.round(lgbm_voting_clf).long()\n",
    "lgbm_voting_clf_score = matthews_corrcoef(y_test,rounded_lgbm_voting_clf_preds)\n",
    "print(f\"Final LGBM-VOTING MCC on test set: {lgbm_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting preds + XGB + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final xgb-LGBM-VOTING MCC on test set: 0.9845939235730832\n"
     ]
    }
   ],
   "source": [
    "xgb_lgbm_voting_clf = (predictions_tensor + lgbm_preds_x + xgb_preds_x)/3\n",
    "rounded_xgb_lgbm_voting_clf_preds = torch.round(xgb_lgbm_voting_clf).long()\n",
    "xgb_lgbm_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_lgbm_voting_clf_preds)\n",
    "print(f\"Final xgb-LGBM-VOTING MCC on test set: {xgb_lgbm_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB + STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds_x.shape,stacking_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_clf = (stacking_preds_x + xgb_preds_x)/2\n",
    "rounded_xgb_voting_clf_preds = torch.round(xgb_voting_clf).long()\n",
    "xgb_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_stacking_clf = (stacking_preds_x + xgb_preds_x)/2\n",
    "rounded_xgb_stacking_clf_preds = torch.round(xgb_stacking_clf).long()\n",
    "xgb_stacking_clf_score = matthews_corrcoef(y_test,rounded_xgb_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB + STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_stacking_clf = (stacking_preds_x + xgb_preds_x + predictions_tensor)/3\n",
    "rounded_xgb_voting_stacking_clf_preds = torch.round(xgb_voting_stacking_clf).long()\n",
    "xgb_voting_stacking_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB + LGBM + STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lgbm_voting_stacking_clf = (stacking_preds_x + xgb_preds_x + lgbm_preds_x + predictions_tensor)/4\n",
    "rounded_xgb_lgbm_voting_stacking_clf_preds = torch.round(xgb_lgbm_voting_stacking_clf).long()\n",
    "xgb_lgbm_voting_stacking_clf_score = matthews_corrcoef(y_test,rounded_xgb_lgbm_voting_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM + STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_voting_stacking_clf = (stacking_preds_x + lgbm_preds_x + predictions_tensor)/3\n",
    "rounded_lgbm_voting_stacking_clf_preds = torch.round(lgbm_voting_stacking_clf).long()\n",
    "xgb_voting_stacking_clf_score = matthews_corrcoef(y_test,rounded_lgbm_voting_stacking_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {lgbm_voting_stacking_clf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  STACKING + VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_voting_clf = (stacking_preds_x + predictions_tensor)/2\n",
    "rounded_stacking_voting_clf_preds = torch.round(stacking_voting_clf).long()\n",
    "stacking_voting_clf_score = matthews_corrcoef(y_test,rounded_stacking_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {stacking_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final XGB-VOTING MCC on test set: {stacking_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_clf = (predictions_tensor + xgb_preds_x)/2\n",
    "rounded_xgb_voting_clf_preds = torch.round(xgb_voting_clf).long()\n",
    "xgb_voting_clf_score = matthews_corrcoef(y_test,rounded_xgb_voting_clf_preds)\n",
    "print(f\"Final XGB-VOTING MCC on test set: {xgb_voting_clf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_d = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING',\n",
    "    'XGB-VOTING','XGB-STACKING','XGB-VOTING-STACKING','XGB-LGBM-VOTING-STACKING','LGBM-VOTING-STACKING','STACKING-VOTING'],\n",
    "    'mcc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,\n",
    "    lgbm_voting_clf_score,xgb_voting_clf_score,xgb_stacking_clf_score,xgb_voting_stacking_clf_score,\n",
    "    xgb_lgbm_voting_stacking_clf_score,lgbm_voting_stacking_clf_score,stacking_voting_clf_score ]\n",
    "})\n",
    "\n",
    "mcc_sorted_d = mcc_d.sort_values(by='mcc_d', ascending=False)\n",
    "mcc_sorted_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algoritm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.984749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB-VOTING</td>\n",
       "      <td>0.984629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb-LGBM-VOTING</td>\n",
       "      <td>0.984594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-LGBM</td>\n",
       "      <td>0.984337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM-VOTING</td>\n",
       "      <td>0.984232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.984125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          algoritm       acc\n",
       "1          xgboost  0.984749\n",
       "5       XGB-VOTING  0.984629\n",
       "3  xgb-LGBM-VOTING  0.984594\n",
       "2         XGB-LGBM  0.984337\n",
       "4      LGBM-VOTING  0.984232\n",
       "0             lgbm  0.984125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING'],\n",
    "    'MCC': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9843371651003854, 0.9841250711521743, 0.9847493710839511)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lgbm_score,lgbm_score,xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algoritm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.984749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-LGBM</td>\n",
       "      <td>0.984272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.984024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algoritm       acc\n",
       "1   xgboost  0.984749\n",
       "2  XGB-LGBM  0.984272\n",
       "0      lgbm  0.984024"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost','XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_a = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING',\n",
    "    'XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,\n",
    "    lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING','VOTING','STACKING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score,voting_score,stacking_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algoritm</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.984749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB-VOTING</td>\n",
       "      <td>0.984629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb-LGBM-VOTING</td>\n",
       "      <td>0.984594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-LGBM</td>\n",
       "      <td>0.984337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM-VOTING</td>\n",
       "      <td>0.984232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.984125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          algoritm       acc\n",
       "1          xgboost  0.984749\n",
       "5       XGB-VOTING  0.984629\n",
       "3  xgb-LGBM-VOTING  0.984594\n",
       "2         XGB-LGBM  0.984337\n",
       "4      LGBM-VOTING  0.984232\n",
       "0             lgbm  0.984125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'XGB-LGBM','xgb-LGBM-VOTING','LGBM-VOTING','XGB-VOTING'],\n",
    "    'acc': [lgbm_score, xgb_score, xgb_lgbm_score ,xgb_lgbm_voting_clf_score,lgbm_voting_clf_score,xgb_voting_clf_score]\n",
    "})\n",
    "\n",
    "accuracy_sorted_b = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({\n",
    "    'algoritm': ['lgbm', 'xgboost', 'cat_boost', 'xgboost + lgbm ', 'xgboost + lgbm + cat_boost',\n",
    "     'xgboost + cat_boost', 'lgbm + cat_boost','neural_network','xgb + nn',\n",
    "     'nn_score + lgbm + xgb + cat','nn_score + lgbm + cat','nn_score + xgb + cat' ],\n",
    "    'acc': [lgbm_score, xgb_score, cat_score,xgb_lgbm_score,xgb_lgbm_cat_score,\n",
    "    xgb_cat_score,lgbm_cat_score, nn_score,xgb_nn_a_score,xgb_lgbm_cat_nn_score, lgbm_cat_nn_score,xgb_cat_nn_score ]\n",
    "})\n",
    "\n",
    "accuracy_sorted = acc.sort_values(by='acc', ascending=False)\n",
    "accuracy_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lgbm_sub = (xgb_preds + lgbm_preds)/2\n",
    "rounded_xgb_lgbm_sub_preds = torch.round(xgb_lgbm_sub).long()\n",
    "rounded_xgb_lgbm_sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in rounded_xgb_lgbm_sub_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 42.7MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[XGBOOST+LGBM] Silver Rubanza, XGBOOST + SUJAY 5000 estimators LGBM optuna tuned params - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM, XGB + VOTING PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2077964,), torch.Size([2077964]), torch.Size([2077964]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_preds.shape,lgbm_preds.shape,xgb_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB + VOTING CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_voting_clf_sub = (xgb_preds + voting_preds)/2\n",
    "rounded_xgb_voting_clf_sub_preds = torch.round(xgb_voting_clf_sub).long()\n",
    "rounded_xgb_voting_clf_sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'submission.csv': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in rounded_xgb_voting_clf_sub_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 45.6MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[XGBOOST+VOTING CLASSIFIER] Silver Rubanza, XGBOOST + VOTING CLASSIFIER PREDS sub 3 - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB + LBM + VOTING CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lgbm_voting_clf_sub = (xgb_preds + voting_preds+ lgbm_preds)/3\n",
    "rounded_xgb_lgbm_voting_clf_sub_preds = torch.round(xgb_lgbm_voting_clf_sub).long()\n",
    "rounded_xgb_voting_clf_sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id class\n",
      "0        3116945     e\n",
      "1        3116946     p\n",
      "2        3116947     p\n",
      "3        3116948     p\n",
      "4        3116949     e\n",
      "...          ...   ...\n",
      "2077959  5194904     p\n",
      "2077960  5194905     p\n",
      "2077961  5194906     p\n",
      "2077962  5194907     e\n",
      "2077963  5194908     e\n",
      "\n",
      "[2077964 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm submission.csv\n",
    "mapping = dict(enumerate(dls.vocab))\n",
    "submit = pd.read_csv(path/'sample_submission.csv')\n",
    "submit['class'] = [mapping[pred.item()] for pred in rounded_xgb_lgbm_voting_clf_sub_preds]\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 46.1MB/s]\n",
      "Successfully submitted to Binary Prediction of Poisonous Mushrooms"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e8 -f submission.csv -m \"[XGBOOST+LGBM+VOTING] Silver Rubanza, XGBOOST + SUJAY LGBM optuna tuned params - lightning  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM + VOTING CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_voting_clf_sub = (lgbm_preds + voting_preds)/2\n",
    "rounded_lgbm_voting_clf_sub_preds = torch.round(lgbm_voting_clf_sub).long()\n",
    "rounded_lgbm_voting_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + xgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_stacking_clf_sub = (xgb_preds + stacking_preds)/2\n",
    "rounded_xgb_stacking_clf_sub_preds = torch.round(xgb_stacking_clf_sub ).long()\n",
    "rounded_xgb_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_stacking_clf_sub = (lgbm_preds + stacking_preds)/2\n",
    "rounded_lgbm_stacking_clf_sub_preds = torch.round(lgbm_stacking_clf_sub ).long()\n",
    "rounded_lgbm_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_stacking_clf_sub = (voting_preds + stacking_preds)/2\n",
    "rounded_voting_stacking_clf_sub_preds = torch.round(voting_stacking_clf_sub ).long()\n",
    "rounded_voting_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_voting_stacking_clf_sub = (voting_preds + stacking_preds + xgb_preds)/3\n",
    "rounded_xgb_voting_stacking_clf_sub_preds = torch.round(xgb_voting_stacking_clf_sub ).long()\n",
    "rounded_xgb_voting_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting + XGB + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lgbm_voting_stacking_clf_sub = (voting_preds + stacking_preds + xgb_preds + lgbm_preds)/4\n",
    "rounded_xgb_lgbm_voting_stacking_clf_sub_preds = torch.round(xgb_lgbm_voting_stacking_clf_sub ).long()\n",
    "rounded_xgb_lgbm_voting_stacking_clf_sub_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Voting + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_voting_stacking_clf_sub = (voting_preds + stacking_preds + lgbm_preds)/3\n",
    "rounded_lgbm_voting_stacking_clf_sub_preds = torch.round(lgbm_voting_stacking_clf_sub ).long()\n",
    "rounded_lgbm_voting_stacking_clf_sub_preds"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
