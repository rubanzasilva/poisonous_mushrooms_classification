{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"},{"sourceId":88591,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":74351,"modelId":99120}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rubanzasilva/fast-ai-gradient-boosting?scriptVersionId=191432655\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Library Imports","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T10:27:26.710009Z","iopub.execute_input":"2024-08-04T10:27:26.710443Z","iopub.status.idle":"2024-08-04T10:27:27.894632Z","shell.execute_reply.started":"2024-08-04T10:27:26.710387Z","shell.execute_reply":"2024-08-04T10:27:27.893144Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install catboost\n%pip install optuna\n%pip install optuna_distributed\n%pip install openfe\n%pip install seaborn\n%pip install xgboost\n%pip install lightgbm\n%pip install fastkaggle\n%pip install h2o\n%pip install -Uqq fastbook\n%pip install polars\n%pip install -q -U autogluon.tabular\n%pip install autogluon\n#ip install --upgrade pip\n%pip install tqdm\n%pip install wandb\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-04T10:27:27.896445Z","iopub.execute_input":"2024-08-04T10:27:27.896918Z","iopub.status.idle":"2024-08-04T10:34:41.660749Z","shell.execute_reply.started":"2024-08-04T10:27:27.896888Z","shell.execute_reply":"2024-08-04T10:34:41.658817Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import fastbook\nfastbook.setup_book()\nfrom fastbook import *\nfrom fastai.tabular.all import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom numpy import random\nfrom tqdm import tqdm\nfrom ipywidgets import interact\n\nfrom fastai.imports import *\nnp.set_printoptions(linewidth=130)\n\n\nfrom pathlib import Path\nimport os\n\n\nfrom sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score,accuracy_score,mean_squared_error, matthews_corrcoef\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, cross_val_score\n\n\n\n#transformers and pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn import set_config\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom xgboost import XGBClassifier\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nfrom catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n\n\n\n\n\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom optuna.visualization import plot_contour\nfrom optuna.visualization import plot_edf\nfrom optuna.visualization import plot_intermediate_values\nfrom optuna.visualization import plot_optimization_history\nfrom optuna.visualization import plot_parallel_coordinate\nfrom optuna.visualization import plot_param_importances\nfrom optuna.visualization import plot_slice\nfrom optuna.samplers import TPESampler\nimport warnings\n\n\nmatplotlib.rc('image', cmap='Greys')\n\nfrom fastkaggle import setup_comp\n\n\n\nfrom openfe import OpenFE, transform\nfrom autogluon.tabular import TabularDataset, TabularPredictor\n\nimport h2o\nfrom h2o.automl import H2OAutoML\n\nimport gc\n\nfrom xgboost import plot_importance\nimport wandb\n\n\n#from IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:34:41.664245Z","iopub.execute_input":"2024-08-04T10:34:41.664861Z","iopub.status.idle":"2024-08-04T10:34:54.907168Z","shell.execute_reply.started":"2024-08-04T10:34:41.664803Z","shell.execute_reply":"2024-08-04T10:34:54.905989Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('/kaggle/input/playground-series-s4e8/')\npath","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:07.345739Z","iopub.execute_input":"2024-08-04T10:39:07.347821Z","iopub.status.idle":"2024-08-04T10:39:07.360206Z","shell.execute_reply.started":"2024-08-04T10:39:07.347766Z","shell.execute_reply":"2024-08-04T10:39:07.358824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(path/'train.csv',index_col='id')\ntest_df = pd.read_csv(path/'test.csv',index_col='id')\nsub_df = pd.read_csv(path/'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:07.59995Z","iopub.execute_input":"2024-08-04T10:39:07.600387Z","iopub.status.idle":"2024-08-04T10:39:29.290488Z","shell.execute_reply.started":"2024-08-04T10:39:07.600355Z","shell.execute_reply":"2024-08-04T10:39:29.2892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dealing with NaN in stem-height\n\nI noticed that the column stem-height has missing values in the test set which are not in the training set.\n\nThe issue is our tabular pandas object takes uses the function fillMissing to fill in our missing values for columns with continuous values. This can be filled in with the median, mode of that column, or a constant, with the default being the median value for that particular column. \n\nHowever, FillMissing is built to only deal with missing values in columns that already have missing values in your training set i.e. for stem-height, which has no missing vaklues in the train set but has missing values in the test set, FillMissing wont know how to deal with them and hence throws an error.\n\nTo resolve this, we can \n\n- We can create a NaN in that particular column so that FillMissing knows how to deal with missing values in that column when it sees them in the test set which is what i have done in this notebook.\nSee the code cell right below.\n- We can also fill in the missing values in the test set with a value such as 0, etc.\n- Finally,We could choose to remove the missing values rows from the test set","metadata":{}},{"cell_type":"code","source":"# Make a copy of the training dataframe to avoid modifying the original\ntrain_df_with_nan = train_df.copy()\n\n# Add a NaN value to a random row in the 'stem-height' column\nrandom_index = np.random.choice(train_df_with_nan.index)\ntrain_df_with_nan.loc[random_index, 'stem-height'] = np.nan\n\n# Verify the NaN was added\nprint(train_df_with_nan['stem-height'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:29.292437Z","iopub.execute_input":"2024-08-04T10:39:29.292816Z","iopub.status.idle":"2024-08-04T10:39:29.83442Z","shell.execute_reply.started":"2024-08-04T10:39:29.292785Z","shell.execute_reply":"2024-08-04T10:39:29.833303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-processing","metadata":{}},{"cell_type":"markdown","source":"### Define categorical and continous variables\n\nI use the fastai [cont_cat_split](https://docs.fast.ai/tabular.core.html#cont_cat_split) function to separate my dataset variables into categorical and continous variables based of the cardinality of my column values.\n\nWe take an argument max card whose default is 20.If the number of unique values is above 20 (max_card value) for a particular column, that column is considered continous and vice versa.","metadata":{}},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(train_df_with_nan, dep_var='class')\nlen(cat_names),len(cont_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:29.835851Z","iopub.execute_input":"2024-08-04T10:39:29.836306Z","iopub.status.idle":"2024-08-04T10:39:29.845443Z","shell.execute_reply.started":"2024-08-04T10:39:29.836275Z","shell.execute_reply":"2024-08-04T10:39:29.844273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split into training and validation set\n\nThe [RandomSplitter](https://docs.fast.ai/data.transforms.html#randomsplitter) below separates the training set into a training and validation set based off the value of the argument valid_pct.","metadata":{}},{"cell_type":"code","source":"splits = RandomSplitter(valid_pct=0.2)(range_of(train_df_with_nan))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:29.848035Z","iopub.execute_input":"2024-08-04T10:39:29.848561Z","iopub.status.idle":"2024-08-04T10:39:30.40529Z","shell.execute_reply.started":"2024-08-04T10:39:29.848529Z","shell.execute_reply":"2024-08-04T10:39:30.403812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TabularPandas\n\nBelow we define a [TabularPandas](https://docs.fast.ai/tabular.core.html#tabularpandas) object. \n\nHere we declare the continous and categorical columns, the dataset splitting strategy, preprocessing steps to apply to our datasets, the dependent variable which is what we are predicting and the type of problem we are optimizing for such as binary classification in this case.","metadata":{}},{"cell_type":"code","source":"to = TabularPandas(train_df_with_nan, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='class',\n                   y_block=CategoryBlock(),\n                   splits=splits)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:30.406794Z","iopub.execute_input":"2024-08-04T10:39:30.407169Z","iopub.status.idle":"2024-08-04T10:39:36.695703Z","shell.execute_reply.started":"2024-08-04T10:39:30.407105Z","shell.execute_reply":"2024-08-04T10:39:36.694467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DataLoaders","metadata":{}},{"cell_type":"markdown","source":"We define a dataloaders which prepares our data for input into our neural network.Here we can define our batch size.","metadata":{}},{"cell_type":"code","source":"dls = to.dataloaders(bs=64)\n#dls = to.dataloaders(bs=1024)\ntest_dl = dls.test_dl(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:36.6972Z","iopub.execute_input":"2024-08-04T10:39:36.697695Z","iopub.status.idle":"2024-08-04T10:39:42.505547Z","shell.execute_reply.started":"2024-08-04T10:39:36.697654Z","shell.execute_reply":"2024-08-04T10:39:42.504259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:42.507453Z","iopub.execute_input":"2024-08-04T10:39:42.507944Z","iopub.status.idle":"2024-08-04T10:39:42.517012Z","shell.execute_reply.started":"2024-08-04T10:39:42.507902Z","shell.execute_reply":"2024-08-04T10:39:42.515536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:42.518997Z","iopub.execute_input":"2024-08-04T10:39:42.519664Z","iopub.status.idle":"2024-08-04T10:39:42.81357Z","shell.execute_reply.started":"2024-08-04T10:39:42.51962Z","shell.execute_reply":"2024-08-04T10:39:42.812265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:39:42.815203Z","iopub.execute_input":"2024-08-04T10:39:42.815593Z","iopub.status.idle":"2024-08-04T10:39:42.864676Z","shell.execute_reply.started":"2024-08-04T10:39:42.815561Z","shell.execute_reply":"2024-08-04T10:39:42.863473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network\n\nBelow we define a tabular_learner which is an extension of the learner class but specific for tabular data. A learner contains everything needed to train the model.","metadata":{}},{"cell_type":"code","source":"learn = tabular_learner(dls, metrics=MatthewsCorrCoef())\n#learn.fit_one_cycle(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:48:42.078161Z","iopub.execute_input":"2024-08-04T10:48:42.078767Z","iopub.status.idle":"2024-08-04T10:48:42.100313Z","shell.execute_reply.started":"2024-08-04T10:48:42.078722Z","shell.execute_reply":"2024-08-04T10:48:42.099086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#learn.fit_one_cycle(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dl = test_dl\nnn_preds = learn.get_preds(dl=dl)\nnn_preds_x = learn.get_preds()[0]\na_preds, _ = learn.get_preds(dl=dl)\nnn_preds_y = a_preds.squeeze(1)\nnn_preds_proba_b = (a_preds[:, 1])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:03:18.763987Z","iopub.execute_input":"2024-08-04T10:03:18.76484Z","iopub.status.idle":"2024-08-04T10:09:46.274121Z","shell.execute_reply.started":"2024-08-04T10:03:18.764801Z","shell.execute_reply":"2024-08-04T10:09:46.273089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds_x.shape,nn_preds_y.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:12:17.094167Z","iopub.execute_input":"2024-08-04T10:12:17.094586Z","iopub.status.idle":"2024-08-04T10:12:17.101665Z","shell.execute_reply.started":"2024-08-04T10:12:17.094557Z","shell.execute_reply":"2024-08-04T10:12:17.100589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds_x.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:12:08.785611Z","iopub.execute_input":"2024-08-04T10:12:08.785968Z","iopub.status.idle":"2024-08-04T10:12:08.826376Z","shell.execute_reply.started":"2024-08-04T10:12:08.785938Z","shell.execute_reply":"2024-08-04T10:12:08.824907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds_x","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:12:57.996678Z","iopub.execute_input":"2024-08-04T10:12:57.997061Z","iopub.status.idle":"2024-08-04T10:12:58.004559Z","shell.execute_reply.started":"2024-08-04T10:12:57.997029Z","shell.execute_reply":"2024-08-04T10:12:58.003665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds_scoring = nn_preds_x[:, 1]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:24:29.861127Z","iopub.execute_input":"2024-08-04T10:24:29.861529Z","iopub.status.idle":"2024-08-04T10:24:29.866252Z","shell.execute_reply.started":"2024-08-04T10:24:29.861501Z","shell.execute_reply":"2024-08-04T10:24:29.86531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds_scoring.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:24:30.197902Z","iopub.execute_input":"2024-08-04T10:24:30.198579Z","iopub.status.idle":"2024-08-04T10:24:30.204697Z","shell.execute_reply.started":"2024-08-04T10:24:30.198547Z","shell.execute_reply":"2024-08-04T10:24:30.203666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rounded_nn_scoring_preds = torch.round(final_preds_scoring).long()\nrounded_nn_scoring_preds","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:25:00.545961Z","iopub.execute_input":"2024-08-04T10:25:00.54634Z","iopub.status.idle":"2024-08-04T10:25:00.555064Z","shell.execute_reply.started":"2024-08-04T10:25:00.54631Z","shell.execute_reply":"2024-08-04T10:25:00.554055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_score = matthews_corrcoef(y_test,rounded_nn_scoring_preds)\nnn_score","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:25:13.758181Z","iopub.execute_input":"2024-08-04T10:25:13.759078Z","iopub.status.idle":"2024-08-04T10:25:13.827107Z","shell.execute_reply.started":"2024-08-04T10:25:13.759045Z","shell.execute_reply":"2024-08-04T10:25:13.826048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = nn_preds_y[:, 1]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:25:39.896919Z","iopub.execute_input":"2024-08-04T10:25:39.897751Z","iopub.status.idle":"2024-08-04T10:25:39.902452Z","shell.execute_reply.started":"2024-08-04T10:25:39.897709Z","shell.execute_reply":"2024-08-04T10:25:39.901428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:25:41.57585Z","iopub.execute_input":"2024-08-04T10:25:41.576541Z","iopub.status.idle":"2024-08-04T10:25:41.582265Z","shell.execute_reply.started":"2024-08-04T10:25:41.576509Z","shell.execute_reply":"2024-08-04T10:25:41.581348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:19:17.573896Z","iopub.execute_input":"2024-08-04T10:19:17.574262Z","iopub.status.idle":"2024-08-04T10:19:17.581351Z","shell.execute_reply.started":"2024-08-04T10:19:17.574223Z","shell.execute_reply":"2024-08-04T10:19:17.580519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.save('mushroom_prediction_model')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:20:48.400971Z","iopub.execute_input":"2024-08-04T10:20:48.401545Z","iopub.status.idle":"2024-08-04T10:20:48.432216Z","shell.execute_reply.started":"2024-08-04T10:20:48.401506Z","shell.execute_reply":"2024-08-04T10:20:48.431316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.load('mushroom_prediction_nn')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:48:48.956866Z","iopub.execute_input":"2024-08-04T10:48:48.957932Z","iopub.status.idle":"2024-08-04T10:48:49.332339Z","shell.execute_reply.started":"2024-08-04T10:48:48.957889Z","shell.execute_reply":"2024-08-04T10:48:49.330822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm submission.csv","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:23:26.894809Z","iopub.execute_input":"2024-08-04T10:23:26.895759Z","iopub.status.idle":"2024-08-04T10:23:27.980764Z","shell.execute_reply.started":"2024-08-04T10:23:26.895718Z","shell.execute_reply":"2024-08-04T10:23:27.979588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rounded_nn_sub_preds = torch.round(final_preds).long()\nrounded_nn_sub_preds","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:25:53.093981Z","iopub.execute_input":"2024-08-04T10:25:53.09492Z","iopub.status.idle":"2024-08-04T10:25:53.107293Z","shell.execute_reply.started":"2024-08-04T10:25:53.094879Z","shell.execute_reply":"2024-08-04T10:25:53.106404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = dict(enumerate(dls.vocab))\nsubmit = pd.read_csv(path/'sample_submission.csv')\nsubmit['class'] = [mapping[pred.item()] for pred in rounded_nn_sub_preds]\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')\nprint(sub)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:25:54.907195Z","iopub.execute_input":"2024-08-04T10:25:54.908094Z","iopub.status.idle":"2024-08-04T10:26:05.726589Z","shell.execute_reply.started":"2024-08-04T10:25:54.908054Z","shell.execute_reply":"2024-08-04T10:26:05.725584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"params_xgb = {\n              \n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'booster': 'gbtree',\n    'n_estimators': 5000,       \n    'learning_rate': 0.55,                   \n    'min_child_weight': 17,      \n    'reg_lambda': 0.2,           \n    'reg_alpha': 7,              \n    'max_bin': 52000,            \n    'colsample_bytree': 0.65,    \n    'max_delta_step': 2,         \n    #'random_state': 0,\n    #'device' : 'cuda',\n    #'devices': '0:1',\n    'tree_method': 'hist'\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:56:11.73557Z","iopub.execute_input":"2024-08-03T12:56:11.735923Z","iopub.status.idle":"2024-08-03T12:56:11.742978Z","shell.execute_reply.started":"2024-08-03T12:56:11.735896Z","shell.execute_reply":"2024-08-03T12:56:11.74171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna_params = {\n              \n    'num_leaves': 375, \n    'learning_rate': 0.0071851097672265855, \n    'n_estimators': 1851, \n    'subsample_for_bin': 104472,\n    'min_child_samples': 454,\n    'reg_alpha': 0.0011093389440775324,\n    'reg_lambda': 0.15936937364526085,\n    'colsample_bytree': 0.4533510196891779,\n    'subsample': 0.9272807625455266,\n    'max_depth': 20,\n    'min_child_weight': 4,\n    'gamma': 0.0033558210410357075,\n    'max_leaves': 873,\n    'device': 'gpu'\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:23:35.486012Z","iopub.execute_input":"2024-08-03T14:23:35.486363Z","iopub.status.idle":"2024-08-03T14:23:35.492004Z","shell.execute_reply.started":"2024-08-03T14:23:35.486334Z","shell.execute_reply":"2024-08-03T14:23:35.491063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef objective(trial):\n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 1.0, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 50, 2000),\n        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 1, 25),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n        'max_leaves': trial.suggest_int('max_leaves', 0, 1000),\n        #'max_bin': trial.suggest_int('max_bin', 200, 1000),\n        #'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n        #'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n        #'tree_method': trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist']),\n        #'use_label_encoder': False,\n        #'eval_metric': 'logloss',\n        'device': 'gpu',\n        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 10, 50)\n    }\n    \n    K_FOLDS = 5  # Number of folds for cross-validation\n    kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n\n    fold_scores = []\n    \n    #for train_index, test_index in kfold.split(train_df):\n    #print(f'train: {len(train_index)} samples, test: {len(test_index)} samples')\n\n    for train_index, val_index in kfold.split(X_train):\n        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n        \n        # Train the model on the current fold\n        \n        xgb_model_fold = xgb.XGBClassifier(**params)\n        xgb_model_fold.fit(X_fold_train, y_fold_train)\n        \n        # Predict probabilities on the validation set for the current fold\n        y_pred_fold = xgb_model_fold.predict(X_fold_val)\n        y_pred_fold_tt = xgb_model_fold.predict(test_dl.xs)\n        \n        # Calculate and store the AUC-ROC score for the current fold\n        score = matthews_corrcoef(y_fold_val, y_pred_fold)\n        fold_scores.append(score)\n        \n        # Calculate the average score across all folds\n        return np.mean(fold_scores)\n\n# Create and run the study\nstudy = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\nstudy.optimize(objective, n_trials=100)\n\nprint('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-03T12:56:25.612812Z","iopub.execute_input":"2024-08-03T12:56:25.613483Z","iopub.status.idle":"2024-08-03T14:12:46.598895Z","shell.execute_reply.started":"2024-08-03T12:56:25.613447Z","shell.execute_reply":"2024-08-03T14:12:46.597934Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nimport xgboost as xgb\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import matthews_corrcoef\nfrom optuna.samplers import TPESampler\n\ndef objective(trial):\n    params = {\n        'max_depth': trial.suggest_int('max_depth', 1, 15),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n        'use_label_encoder': False,\n        'eval_metric': 'logloss',\n        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 10, 50)\n    }\n    \n    K_FOLDS = 5  # Number of folds for cross-validation\n    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n\n    fold_scores = []\n\n    for train_index, val_index in skf.split(X_train, y_train):\n        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n        \n        # Train the model on the current fold\n        xgb_model_fold = xgb.XGBClassifier(**params)\n        xgb_model_fold.fit(X_fold_train, y_fold_train)\n        \n        # Predict on the validation set for the current fold\n        y_pred_fold = xgb_model_fold.predict(X_fold_val)\n        \n        # Calculate and store the Matthews Correlation Coefficient for the current fold\n        score = matthews_corrcoef(y_fold_val, y_pred_fold)\n        fold_scores.append(score)\n        \n        print(f\"Fold {fold} MCC: {score}\")\n\n    # Return the average score across all folds\n    mean_score = np.mean(fold_scores)\n    print(f\"Mean MCC: {mean_score}\")\n    return mean_score\n\n# Create and run the study\nstudy = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\nstudy.optimize(objective, n_trials=100)\n\nprint('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:12:47.120063Z","iopub.execute_input":"2024-08-03T14:12:47.120771Z","iopub.status.idle":"2024-08-03T14:12:47.12581Z","shell.execute_reply.started":"2024-08-03T14:12:47.120745Z","shell.execute_reply":"2024-08-03T14:12:47.124974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params = {\n    'num_leaves': 375, 'learning_rate': 0.0071851097672265855, 'n_estimators': 1851, 'subsample_for_bin': 104472, 'min_child_samples': 454, 'reg_alpha': 0.0011093389440775324, 'reg_lambda': 0.15936937364526085, 'colsample_bytree': 0.4533510196891779, 'subsample': 0.9272807625455266, 'max_depth': 20, 'min_child_weight': 4, 'gamma': 0.0033558210410357075, 'max_leaves': 873}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nxgb_model = xgb.XGBClassifier(**optuna_params)\nxgb_model = xgb_model.fit(X_train, y_train)\n\nxgb_preds = tensor(xgb_model.predict(test_dl.xs))\n\nxgb_preds_x = tensor(xgb_model.predict(X_test))\n\nxgb_score = matthews_corrcoef(y_test,xgb_preds_x)\nxgb_score","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:23:36.986693Z","iopub.execute_input":"2024-08-03T14:23:36.987295Z","iopub.status.idle":"2024-08-03T14:25:22.849455Z","shell.execute_reply.started":"2024-08-03T14:23:36.987267Z","shell.execute_reply":"2024-08-03T14:25:22.848575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:29:30.362807Z","iopub.execute_input":"2024-08-03T14:29:30.363695Z","iopub.status.idle":"2024-08-03T14:29:31.449624Z","shell.execute_reply.started":"2024-08-03T14:29:30.363661Z","shell.execute_reply":"2024-08-03T14:29:31.448609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = dict(enumerate(dls.vocab))\nsubmit = pd.read_csv(path/'sample_submission.csv')\nsubmit['class'] = [mapping[pred.item()] for pred in xgb_preds]\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')\nprint(sub)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:25:55.80187Z","iopub.execute_input":"2024-08-03T14:25:55.802705Z","iopub.status.idle":"2024-08-03T14:26:06.153423Z","shell.execute_reply.started":"2024-08-03T14:25:55.802672Z","shell.execute_reply":"2024-08-03T14:26:06.15246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef objective(trial):\n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 1, 15),\n        'device_type': 'gpu'\n    }\n    \n    K_FOLDS = 5  # Number of folds for cross-validation\n    kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n\n    fold_scores = []\n    \n    #for train_index, test_index in kfold.split(train_df):\n    #print(f'train: {len(train_index)} samples, test: {len(test_index)} samples')\n\n    for train_index, val_index in kfold.split(X_train):\n        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n        \n        # Train the model on the current fold\n        lgb_model_fold = lgb.LGBMClassifier(**params)  # Use params, not lgbm_params\n        lgb_model_fold.fit(X_fold_train, y_fold_train)\n        \n        y_pred_fold = lgb_model_fold.predict(X_fold_val)\n        y_pred_fold_tt = lgb_model_fold.predict(test_dl.xs)\n        \n        # Calculate and store the AUC-ROC score for the current fold\n        score = matthews_corrcoef(y_fold_val, y_pred_fold)\n        fold_scores.append(score)\n        \n        # Calculate the average score across all folds\n        return np.mean(fold_scores)\n\n# Create and run the study\nstudy = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\nstudy.optimize(objective, n_trials=100)\n\nprint('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:52:46.683842Z","iopub.execute_input":"2024-08-03T14:52:46.684216Z"},"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef objective(trial):\n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 1, 15),\n        'device_type': 'gpu'\n    }\n    \n    K_FOLDS = 5  # Number of folds for cross-validation\n    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n    fold_scores = []\n    \n    for train_index, val_index in skf.split(X_train, y_train):\n        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n        \n        # Train the model on the current fold\n        lgb_model_fold = lgb.LGBMClassifier(**params)\n        lgb_model_fold.fit(X_fold_train, y_fold_train)\n        \n        y_pred_fold = lgb_model_fold.predict(X_fold_val)\n        \n        # Calculate and store the MCC score for the current fold\n        score = matthews_corrcoef(y_fold_val, y_pred_fold)\n        fold_scores.append(score)\n    \n    # Calculate the average score across all folds\n    return np.mean(fold_scores)\n\n# Create and run the study\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\nstudy.optimize(objective, n_trials=100, show_progress_bar=True)\n\nprint('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:25:47.937662Z","iopub.execute_input":"2024-08-04T04:25:47.9381Z","iopub.status.idle":"2024-08-04T05:38:56.792787Z","shell.execute_reply.started":"2024-08-04T04:25:47.938067Z","shell.execute_reply":"2024-08-04T05:38:56.791871Z"},"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T05:38:56.794621Z","iopub.execute_input":"2024-08-04T05:38:56.795016Z","iopub.status.idle":"2024-08-04T05:38:56.801745Z","shell.execute_reply.started":"2024-08-04T05:38:56.794981Z","shell.execute_reply":"2024-08-04T05:38:56.800858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import matthews_corrcoef\nimport numpy as np\nimport lightgbm as lgb\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\nfrom tqdm import tqdm\n\ndef objective(trial):\n    params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 1, 15),\n        'device_type': 'gpu'\n    }\n    \n    K_FOLDS = 5  # Number of folds for cross-validation\n    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n    fold_scores = []\n    \n    for train_index, val_index in skf.split(X_train, y_train):\n        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n        \n        # Train the model on the current fold with early stopping\n        lgb_model_fold = lgb.LGBMClassifier(**params)\n        lgb_model_fold.fit(\n            X_fold_train, y_fold_train,\n            eval_set=[(X_fold_val, y_fold_val)],\n            callbacks=[\n                #LightGBMPruningCallback(trial, 'binary_logloss'),\n                lgb.early_stopping(stopping_rounds=50, verbose=False)\n            ]\n        )\n        \n        y_pred_fold = lgb_model_fold.predict(X_fold_val)\n        #y_pred_fold_tt = lgb_model_fold.predict(test_dl.xs)\n        \n        # Calculate and store the MCC score for the current fold\n        score = matthews_corrcoef(y_fold_val, y_pred_fold)\n        fold_scores.append(score)\n    \n    # Calculate the average score across all folds\n    return np.mean(fold_scores)\n\n# Create and run the study with a progress bar\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\nstudy.optimize(objective, n_trials=100, show_progress_bar=True)\n\nprint('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T05:43:37.678838Z","iopub.execute_input":"2024-08-04T05:43:37.67918Z","iopub.status.idle":"2024-08-04T07:07:30.888182Z","shell.execute_reply.started":"2024-08-04T05:43:37.679152Z","shell.execute_reply":"2024-08-04T07:07:30.887138Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install optuna-integration","metadata":{"execution":{"iopub.status.busy":"2024-08-04T05:40:12.284117Z","iopub.execute_input":"2024-08-04T05:40:12.284472Z","iopub.status.idle":"2024-08-04T05:40:26.610401Z","shell.execute_reply.started":"2024-08-04T05:40:12.284441Z","shell.execute_reply":"2024-08-04T05:40:26.609148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params = study.best_trial.params\nbest_model = xgb.XGBClassifier(**best_params)\nbest_model.fit(X_train, y_train)\ny_pred = best_model.predict(X_test)\nfinal_score = matthews_corrcoef(y_test, y_pred)\nprint(f\"Final MCC on test set: {final_score}\")","metadata":{},"execution_count":null,"outputs":[]}]}